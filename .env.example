# LLM Provider Configuration
# choose provider: "google" or "openai" (llm-client supports both shapes)
LLM_PROVIDER=google

# Google AI Studio Configuration
# Get your API key from: https://aistudio.google.com/app/apikey
# For Google GenAI REST endpoint - DO NOT include ?key= in the URL
LLM_API_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
LLM_API_KEY=your_google_api_key_here

# Model Configuration  
# Available models: gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash
LLM_MODEL=gemini-2.0-flash

# Application Configuration
# Maximum allowed input characters (sanity check)
MAX_INPUT_CHARS=4000

# Optional: Logging level (debug, info, warn, error)
LOG_LEVEL=info

# Optional: Server port (default: 3000)
PORT=3000
